{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification using SVM and Naive Bayes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnsCzYkln2fQrGRY+EhYhg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anurag38/NLP-Practicals/blob/main/Practical%206%20-%20Text%20Classification/Text_Classification_using_SVM_and_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV9yBdmqjdJw"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.wrappers import FastText\n",
        "from gensim.models import FastText\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZgP_cbcjdJ8"
      },
      "source": [
        "import itertools\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "#from glove import Corpus, Glove\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "# from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "#from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4mzkpFjdKC"
      },
      "source": [
        "# provide sql-like data manipulation tools. very handy.\n",
        "import pandas as pd \n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# high dimensional vector computing library.\n",
        "import numpy as np \n",
        "from copy import deepcopy\n",
        "from string import punctuation\n",
        "from random import shuffle\n",
        "\n",
        "import gensim\n",
        "\n",
        "# the word2vec model gensim class\n",
        "from gensim.models.word2vec import Word2Vec \n",
        "\n",
        "# we'll talk about this down below\n",
        "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "\n",
        "# a tweet tokenizer from nltk.\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJlK_bclxRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262bc0df-9782-4c29-ca6e-939e291bae7b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bapfnCCwjdKF"
      },
      "source": [
        "train= pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/NLP/Practical 6/taska.txt',header=None,sep='\\t',names=['id','text','class'])\n",
        "#valid_df= pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/AMI/dataset/agr_en_dev.csv',header=None,names=['id','text','class'])\n",
        "\n",
        "#test_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/AMI/dataset/agr_en_fb_gold.csv',header=None,names=['id','text','class'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQbm7GAUu56L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b23482f-b28a-45c1-85c5-5c0bb927def9"
      },
      "source": [
        "train.info()\n",
        "train.head()\n",
        "train['class'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13240 entries, 0 to 13239\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      13240 non-null  int64 \n",
            " 1   text    13240 non-null  object\n",
            " 2   class   13240 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 310.4+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOT    8840\n",
              "OFF    4400\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsyPoHQmjdKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f0d7873e-0dfe-408a-eeb6-c5f38f247a2f"
      },
      "source": [
        "import re\n",
        "def clean_text(comment):\n",
        "    comment = comment.strip().strip('\"')\n",
        "    comment = comment.replace('_', ' ')\n",
        "    comment = comment.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "    comment = comment.replace('\\\\n', ' ')\n",
        "    comment = comment.replace('\\\\n', ' ')\n",
        "    comment = comment.lower()\n",
        "    comment = re.sub(r'@[A-Za-z0-9]+','',comment)\n",
        "    \n",
        "    comment = re.sub('https?://[A-Za-z0-9./]+','',comment)\n",
        "    commment = re.sub(\"[^a-zA-Z]\", \" \", comment)\n",
        "    comment = re.sub(r'[^\\w\\s]','',comment)\n",
        "\n",
        "    \n",
        "    return comment\n",
        "\n",
        "train['text'] = train['text'].fillna(\"something\").values\n",
        "train['ctext']=train['text'].apply(clean_text)\n",
        "#train_df['ctext']=train_df['text']\n",
        "#valid_df['ctext']=valid_df['text'].apply(clean_text)\n",
        "#test_df['ctext']=test_df['text'].apply(clean_text)\n",
        "train.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>go home youre drunk  maga trump2020  url</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>obama wanted liberals amp illegals to move i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                              ctext\n",
              "0  86426  ...   she should ask a few native americans what th...\n",
              "1  90194  ...           go home youre drunk  maga trump2020  url\n",
              "2  16820  ...  amazon is investigating chinese employees who ...\n",
              "3  62688  ...   someone shouldvetaken this piece of shit to a...\n",
              "4  43605  ...    obama wanted liberals amp illegals to move i...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfFib4IVzhMa"
      },
      "source": [
        "#tr=train_df[train_df['text']=='something']\n",
        "#tr.head()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSZtRWUEjdKL"
      },
      "source": [
        "#train_df['text'] = train_df['text'].fillna(\"something\").values\n",
        "train['class'] = train['class'].map({'OFF': 0, 'NOT': 1})\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYRwceo6-qsL"
      },
      "source": [
        "train_df, test_df = train_test_split(train,test_size = 0.1)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-LT_MCQjdKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abf8205-9258-464d-99b5-11cfeeca61ec"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "train_df['tokenized_sents'] = train_df.apply(lambda row: nltk.word_tokenize(row['ctext']), axis=1)\n",
        "test_df['tokenized_sents'] = test_df.apply(lambda row: nltk.word_tokenize(row['ctext']), axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4wHg32CZAgdS",
        "outputId": "b06f127e-0328-4b99-ef53-c0f08502d7e6"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>ctext</th>\n",
              "      <th>tokenized_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>44209</td>\n",
              "      <td>@USER @USER what a baby! URL</td>\n",
              "      <td>1</td>\n",
              "      <td>what a baby url</td>\n",
              "      <td>[what, a, baby, url]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2213</th>\n",
              "      <td>63179</td>\n",
              "      <td>@USER how crazy youre a professor and you lie ...</td>\n",
              "      <td>1</td>\n",
              "      <td>how crazy youre a professor and you lie and s...</td>\n",
              "      <td>[how, crazy, youre, a, professor, and, you, li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3548</th>\n",
              "      <td>41881</td>\n",
              "      <td>@USER Master of None was so fucking good.</td>\n",
              "      <td>0</td>\n",
              "      <td>master of none was so fucking good</td>\n",
              "      <td>[master, of, none, was, so, fucking, good]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4810</th>\n",
              "      <td>80502</td>\n",
              "      <td>@USER I can see how frustrating that is. Conse...</td>\n",
              "      <td>1</td>\n",
              "      <td>i can see how frustrating that is conservativ...</td>\n",
              "      <td>[i, can, see, how, frustrating, that, is, cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>65060</td>\n",
              "      <td>@USER @USER Then there should be no problem ha...</td>\n",
              "      <td>1</td>\n",
              "      <td>then there should be no problem having kavan...</td>\n",
              "      <td>[then, there, should, be, no, problem, having,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                    tokenized_sents\n",
              "98    44209  ...                               [what, a, baby, url]\n",
              "2213  63179  ...  [how, crazy, youre, a, professor, and, you, li...\n",
              "3548  41881  ...         [master, of, none, was, so, fucking, good]\n",
              "4810  80502  ...  [i, can, see, how, frustrating, that, is, cons...\n",
              "1351  65060  ...  [then, there, should, be, no, problem, having,...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FkdPexWjdKQ"
      },
      "source": [
        "x_train=train_df['tokenized_sents']\n",
        "x_test=test_df['tokenized_sents']\n",
        "\n",
        "y_train=train_df['class']\n",
        "y_test=test_df['class']\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PytDaKaMjdKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4ec0da-ad65-4757-ec84-47bbdb7d1fd5"
      },
      "source": [
        "def labelizeTweets(tweets, label_type):\n",
        "    labelized = []\n",
        "    for i,v in tqdm(enumerate(tweets)):\n",
        "        label = '%s_%s'%(label_type,i)\n",
        "        labelized.append(LabeledSentence(v, [label]))\n",
        "    return labelized\n",
        "\n",
        "x_train = labelizeTweets(x_train, 'TRAIN')\n",
        "\n",
        "x_test = labelizeTweets(x_test, 'TEST')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  \"\"\"\n",
            "11916it [00:00, 201536.04it/s]\n",
            "1324it [00:00, 6935.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZoOxMHjdKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f08800a-c44d-4a87-c916-22a4efd6caa9"
      },
      "source": [
        "#tweet_w2v = FastText(size=400, min_count=1,sg=1)\n",
        "tweet_w2v = Word2Vec(size=300, min_count=1,sg=1) #SKIPGRAM\n",
        "tweet_w2v.build_vocab([x.words for x in tqdm(x_train)])\n",
        "tweet_w2v.train([x.words for x in tqdm(x_train)],total_examples=len(x_train),epochs=10)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11916/11916 [00:00<00:00, 1227028.54it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11916/11916 [00:00<00:00, 1595967.76it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1815059, 2330450)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_42crwv7-6x",
        "outputId": "f0a86dd0-efac-4a2b-b179-10584578f0ea"
      },
      "source": [
        "tweet_w2v['hello']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00314472, -0.13065872,  0.08991455, -0.12199759, -0.00978568,\n",
              "       -0.04098298,  0.08693017, -0.06024295,  0.0075525 ,  0.07726957,\n",
              "        0.07107034, -0.13799596,  0.05166671, -0.09340643,  0.06837691,\n",
              "        0.03982214, -0.01618377, -0.12473425, -0.12859814, -0.03213874,\n",
              "       -0.01839467,  0.04907308,  0.01367785,  0.04298516,  0.09651073,\n",
              "        0.03812995,  0.13936377, -0.09867909,  0.09043328, -0.18033941,\n",
              "        0.01383958, -0.20557696,  0.06169865,  0.01623362,  0.08468635,\n",
              "       -0.1258927 ,  0.0059935 ,  0.0166661 , -0.01805684,  0.16648574,\n",
              "       -0.06697562,  0.12380682,  0.01091013, -0.06491988, -0.10310332,\n",
              "       -0.17081273,  0.04038997,  0.2096578 , -0.24963261,  0.04399724,\n",
              "       -0.04198681,  0.0733701 ,  0.08029886, -0.0387301 , -0.04316225,\n",
              "        0.17143124,  0.07347972,  0.0284666 , -0.05435783, -0.09613962,\n",
              "       -0.08737934, -0.0416421 ,  0.06756239, -0.01392502,  0.02203156,\n",
              "        0.03446636, -0.04230212, -0.03806321,  0.12149289,  0.00463667,\n",
              "       -0.03262297, -0.02133086, -0.29613286, -0.04402392,  0.01468749,\n",
              "        0.00752582,  0.00515463,  0.1095597 ,  0.2968143 ,  0.11026744,\n",
              "       -0.15424158,  0.12643985,  0.08922472, -0.05821566,  0.20915878,\n",
              "       -0.10790168, -0.04599273,  0.07285976, -0.02045071, -0.05012241,\n",
              "       -0.01448269,  0.00906761, -0.19044018,  0.05241682,  0.12533726,\n",
              "       -0.09895375, -0.03396562,  0.00434481, -0.04736375, -0.13257779,\n",
              "       -0.00394998, -0.08032677,  0.08691293,  0.10901335, -0.18101883,\n",
              "       -0.03006742,  0.1291645 , -0.03676669,  0.13923617, -0.07193936,\n",
              "       -0.0919394 , -0.12320528,  0.0208341 ,  0.00463093, -0.00463078,\n",
              "       -0.11053008, -0.02869882, -0.09401163,  0.04004475,  0.10788726,\n",
              "        0.05866287,  0.01455376, -0.07991536, -0.04157459,  0.04966598,\n",
              "        0.02525671,  0.05350529, -0.04623649, -0.13079348, -0.02578956,\n",
              "       -0.05716039,  0.00181437,  0.00885565, -0.03900167,  0.0297865 ,\n",
              "        0.06220865, -0.06362937, -0.09440362,  0.05604972,  0.03903452,\n",
              "        0.12358894, -0.02810586, -0.10851552,  0.03608559,  0.07332735,\n",
              "       -0.08929904, -0.11661168,  0.04866149,  0.04426988,  0.06181067,\n",
              "        0.01431375,  0.00525761, -0.19448401, -0.23941216, -0.03812233,\n",
              "        0.03716986,  0.03704713,  0.101156  ,  0.11734018,  0.01014827,\n",
              "        0.04583425, -0.03557092, -0.11864194, -0.03755816,  0.02913573,\n",
              "        0.00844995,  0.11588091, -0.09684059,  0.121332  , -0.1432374 ,\n",
              "        0.10666657, -0.02957987,  0.05295937, -0.08749959,  0.03240258,\n",
              "        0.06296821,  0.01120032,  0.07378779,  0.06664228,  0.02880649,\n",
              "       -0.09517857,  0.01479433,  0.12143822,  0.06709668,  0.00114931,\n",
              "        0.07936523,  0.05349196,  0.01516782,  0.15299255, -0.08198348,\n",
              "       -0.00558164, -0.01654886, -0.05257548,  0.10838428,  0.09800468,\n",
              "       -0.02278124, -0.00456266,  0.23386796, -0.02540107,  0.02022786,\n",
              "        0.00952097,  0.00436007, -0.08580144, -0.15988296,  0.0520274 ,\n",
              "       -0.18993334, -0.08150498,  0.00789235, -0.04298046, -0.14927956,\n",
              "        0.02600785,  0.03071522,  0.00180434, -0.00274794,  0.19826049,\n",
              "        0.05842279,  0.04242078, -0.05049535, -0.21382023, -0.22291085,\n",
              "        0.19319141, -0.19765334, -0.0532678 , -0.01802116,  0.12152091,\n",
              "       -0.07832753, -0.00193109,  0.12662433, -0.11732334, -0.18976262,\n",
              "        0.04589694, -0.0366009 , -0.00065684, -0.03848116, -0.1171793 ,\n",
              "        0.08929868,  0.00245892, -0.01441938, -0.05747909, -0.05920038,\n",
              "        0.0462721 ,  0.07733268,  0.07033057, -0.17677857,  0.04952272,\n",
              "        0.02830783, -0.0971057 ,  0.1195737 , -0.03179878, -0.0421052 ,\n",
              "        0.22375089,  0.03376535,  0.1288204 , -0.09790009,  0.11354902,\n",
              "        0.02612249,  0.05099332,  0.22490472,  0.22734787,  0.0999711 ,\n",
              "       -0.03338713,  0.07541032,  0.09910852,  0.01622492,  0.03861242,\n",
              "        0.05976127, -0.06833421, -0.03853914, -0.03321198,  0.02466842,\n",
              "        0.03429099,  0.06884188,  0.12907867, -0.06847176,  0.0665767 ,\n",
              "        0.08591092, -0.04853317,  0.10089768,  0.01208634, -0.14126289,\n",
              "       -0.06357308,  0.01080376, -0.08149426, -0.08295683,  0.39843002,\n",
              "        0.11112975, -0.03882346,  0.02191785,  0.05999793, -0.05816391,\n",
              "        0.12240974,  0.1071295 ,  0.04799751, -0.00771573, -0.03420164,\n",
              "       -0.03410066,  0.00155467,  0.05498887,  0.09134821, -0.05387194],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "LZtGGuve724c",
        "outputId": "df1f2aaa-054e-41d4-9f00-496c82987f6b"
      },
      "source": [
        "tweet_w2v['anurag']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-12ffe7e0ca66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_w2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anurag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 )\n\u001b[0;32m-> 1422\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'anurag' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lku_BDNEjdKb"
      },
      "source": [
        "#tweet_w2v.save('off-sg.vec')\n",
        "#tweet_w2v.save('fb-en-w2vec-cbow.bin')\n",
        "#tweet_w2v.wv.save_word2vec_format('fb-hi-w2vec-cbow.txt')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyiVN7Yh8ESd"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7VFpm-VjdKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cafbd1d-cf5b-4f95-ff6a-35645a21ce0b"
      },
      "source": [
        "print ('building tf-idf matrix ...')\n",
        "vectorizer = TfidfVectorizer(min_df=1)\n",
        "#matrix = vectorizer.fit_transform(x_train)\n",
        "matrix = vectorizer.fit_transform(train_df['ctext'])\n",
        "\n",
        "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
        "print ('vocab size :', len(tfidf))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tf-idf matrix ...\n",
            "vocab size : 19483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOnxSbRKBOBF"
      },
      "source": [
        "#tweet_w2v['messi']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSS_6lDDjdKi"
      },
      "source": [
        "#tweet_w2v=FastText.load('fb-en-fasttext-sg.vec')\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ei0f2FjdKk"
      },
      "source": [
        "def buildWordVector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += tweet_w2v[word].reshape((1, size)) * tfidf[word]\n",
        "            count += 1.\n",
        "        except KeyError: # handling the case where the token is not\n",
        "                         # in the corpus. useful for testing.\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23vFtP_1jdKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744b9815-026c-4ec5-f353-b9c4bf958221"
      },
      "source": [
        "#tweet_w2v=Word2Vec.load('D:/ps/model/English/fasttext/coling-fasttext-eng-cbow.bin')\n",
        "#from gensim.models.wrappers import FastText\n",
        "\n",
        "#tweet_w2v= FastText.load_fasttext_format('D:/ps/model/English/fasttext/coling-fasttext-eng-cbow')\n",
        "\n",
        "n_dim=300\n",
        "from sklearn.preprocessing import scale\n",
        "train_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_train))])\n",
        "train_vecs_w2v = scale(train_vecs_w2v)\n",
        "\n",
        "\n",
        "\n",
        "test_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_test))])\n",
        "test_vecs_w2v = scale(test_vecs_w2v)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "11916it [00:02, 4180.34it/s]\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "1324it [00:00, 3892.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePPCgrM336bl"
      },
      "source": [
        "###Shape\n",
        "train_vecs_w2v.shape\n",
        "test_vecs_w2v.shape\n",
        "train_vecs_w2v[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70_llh8XjdKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533d1588-7228-4f86-a788-c0850f70173a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "\n",
        "clf1 = LinearSVC()\n",
        "clf2 = GaussianNB()\n",
        "\n",
        "clf1.fit(train_vecs_w2v, y_train)\n",
        "clf2.fit(train_vecs_w2v, y_train)\n",
        "\n",
        "#print(clf.score(valid_vecs_w2v, y_valid))\n",
        "print(\"SVM: \",clf1.score(test_vecs_w2v,y_test))\n",
        "print(\"Naive Bayes: \",clf2.score(test_vecs_w2v,y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM:  0.6774924471299094\n",
            "Naive Bayes:  0.5317220543806647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9f-V9G72W5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e665e59-fefe-4993-af98-c4d81ed220a9"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred_class = clf1.predict(test_vecs_w2v)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
        "print (metrics.precision_score(y_test, y_pred_class,average= 'weighted'))\n",
        "print(metrics.recall_score(y_test, y_pred_class,average= 'weighted'))\n",
        "print (metrics.f1_score(y_test, y_pred_class, average= 'weighted'))\n",
        "#print (metrics.f1_score(y_test, y_pred_class))\n",
        "print(metrics.classification_report(y_test, y_pred_class,target_names=['0','1']))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6774924471299094\n",
            "[[141 272]\n",
            " [155 756]]\n",
            "0.6545999294197039\n",
            "0.6774924471299094\n",
            "0.6606122768541524\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.34      0.40       413\n",
            "           1       0.74      0.83      0.78       911\n",
            "\n",
            "    accuracy                           0.68      1324\n",
            "   macro avg       0.61      0.59      0.59      1324\n",
            "weighted avg       0.65      0.68      0.66      1324\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmLp_NwyeQKh",
        "outputId": "3feae890-63d2-4109-e0ff-d412d421229e"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_pred_class = clf2.predict(test_vecs_w2v)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
        "print (metrics.precision_score(y_test, y_pred_class,average= 'weighted'))\n",
        "print(metrics.recall_score(y_test, y_pred_class,average= 'weighted'))\n",
        "print (metrics.f1_score(y_test, y_pred_class, average= 'weighted'))\n",
        "#print (metrics.f1_score(y_test, y_pred_class))\n",
        "print(metrics.classification_report(y_test, y_pred_class,target_names=['0','1']))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5317220543806647\n",
            "[[322  91]\n",
            " [529 382]]\n",
            "0.6737189467464182\n",
            "0.5317220543806647\n",
            "0.5387567595617556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.78      0.51       413\n",
            "           1       0.81      0.42      0.55       911\n",
            "\n",
            "    accuracy                           0.53      1324\n",
            "   macro avg       0.59      0.60      0.53      1324\n",
            "weighted avg       0.67      0.53      0.54      1324\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS-3NKcifgzG"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}