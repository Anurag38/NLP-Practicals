{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Tagging with HMM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQK2wO9ILqnU+DeeKZtqCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anurag38/NLP-Practicals/blob/main/Practical%2011%20-%20Sequence%20Tagging%20with%20HMM/Sequence_Tagging_with_HMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9IoxqxNriGG",
        "outputId": "e9fe0060-a1d4-43f7-c67e-c271e647deb6"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint, time\n",
        " \n",
        "#download the treebank corpus from nltk\n",
        "nltk.download('treebank')\n",
        " \n",
        "#download the universal tagset from nltk\n",
        "nltk.download('universal_tagset')\n",
        " \n",
        "# reading the Treebank tagged sentences\n",
        "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
        " \n",
        "#print the first two sentences along with tags\n",
        "print(nltk_data[:2])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3uhSKAcrptV",
        "outputId": "6fd587ce-678b-4399-d7b9-94fdd119f977"
      },
      "source": [
        "for sent in nltk_data[:2]:\n",
        "  for tuple in sent:\n",
        "    print(tuple)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Pierre', 'NOUN')\n",
            "('Vinken', 'NOUN')\n",
            "(',', '.')\n",
            "('61', 'NUM')\n",
            "('years', 'NOUN')\n",
            "('old', 'ADJ')\n",
            "(',', '.')\n",
            "('will', 'VERB')\n",
            "('join', 'VERB')\n",
            "('the', 'DET')\n",
            "('board', 'NOUN')\n",
            "('as', 'ADP')\n",
            "('a', 'DET')\n",
            "('nonexecutive', 'ADJ')\n",
            "('director', 'NOUN')\n",
            "('Nov.', 'NOUN')\n",
            "('29', 'NUM')\n",
            "('.', '.')\n",
            "('Mr.', 'NOUN')\n",
            "('Vinken', 'NOUN')\n",
            "('is', 'VERB')\n",
            "('chairman', 'NOUN')\n",
            "('of', 'ADP')\n",
            "('Elsevier', 'NOUN')\n",
            "('N.V.', 'NOUN')\n",
            "(',', '.')\n",
            "('the', 'DET')\n",
            "('Dutch', 'NOUN')\n",
            "('publishing', 'VERB')\n",
            "('group', 'NOUN')\n",
            "('.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71C47HWvr1ir"
      },
      "source": [
        "train_set,test_set =train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s79S3arLr4hc",
        "outputId": "f821cfb6-5371-47b2-fbfe-29b1ccbe2691"
      },
      "source": [
        "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
        "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
        "print(len(train_tagged_words))\n",
        "print(len(test_tagged_words))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80310\n",
            "20366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9OkvUFKr6ng",
        "outputId": "f942f633-df90-4c62-aed4-1b67359aa747"
      },
      "source": [
        "#use set datatype to check how many unique tags are present in training data\n",
        "tags = {tag for word,tag in train_tagged_words}\n",
        "print(len(tags))\n",
        "print(tags)\n",
        " \n",
        "# check total words in vocabulary\n",
        "vocab = {word for word,tag in train_tagged_words}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "{'X', 'DET', 'CONJ', 'NOUN', 'PRT', 'NUM', 'ADJ', 'ADV', 'PRON', 'ADP', 'VERB', '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6wWleChr8VQ"
      },
      "source": [
        "# compute Emission Probability\n",
        "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
        "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
        "    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n",
        "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
        "#now calculate the total number of times the passed word occurred as the passed tag.\n",
        "    count_w_given_tag = len(w_given_tag_list)\n",
        " \n",
        "     \n",
        "    return (count_w_given_tag, count_tag)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXVPRb26r-vj"
      },
      "source": [
        "# compute  Transition Probability\n",
        "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
        "    tags = [pair[1] for pair in train_bag]\n",
        "    count_t1 = len([t for t in tags if t==t1])\n",
        "    count_t2_t1 = 0\n",
        "    for index in range(len(tags)-1):\n",
        "        if tags[index]==t1 and tags[index+1] == t2:\n",
        "            count_t2_t1 += 1\n",
        "    return (count_t2_t1, count_t1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBxuQ4JOsA28",
        "outputId": "4d9cb6b1-6b59-4869-9d4e-47eec9a329be"
      },
      "source": [
        "# creating t x t transition matrix of tags, t= no of tags\n",
        "# Matrix(i, j) represents P(jth tag after the ith tag)\n",
        " \n",
        "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
        "for i, t1 in enumerate(list(tags)):\n",
        "    for j, t2 in enumerate(list(tags)): \n",
        "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
        " \n",
        "print(tags_matrix)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.57255405e-02 5.68902567e-02 1.03786280e-02 6.16951771e-02\n",
            "  1.85085520e-01 3.07514891e-03 1.76821072e-02 2.57543717e-02\n",
            "  5.41995019e-02 1.42225638e-01 2.06419379e-01 1.60868734e-01]\n",
            " [4.51343954e-02 6.03708485e-03 4.31220367e-04 6.35906279e-01\n",
            "  2.87480245e-04 2.28546783e-02 2.06410810e-01 1.20741697e-02\n",
            "  3.30602261e-03 9.91806854e-03 4.02472317e-02 1.73925534e-02]\n",
            " [9.33040585e-03 1.23490669e-01 5.48847427e-04 3.49066973e-01\n",
            "  4.39077942e-03 4.06147093e-02 1.13611415e-01 5.70801310e-02\n",
            "  6.03732169e-02 5.59824370e-02 1.50384188e-01 3.51262353e-02]\n",
            " [2.88252197e-02 1.31063312e-02 4.24540639e-02 2.62344331e-01\n",
            "  4.39345129e-02 9.14395228e-03 1.25838192e-02 1.68945398e-02\n",
            "  4.65906132e-03 1.76826611e-01 1.49133503e-01 2.40094051e-01]\n",
            " [1.21330721e-02 1.01369865e-01 2.34833662e-03 2.50489235e-01\n",
            "  1.17416831e-03 5.67514673e-02 8.29745606e-02 9.39334650e-03\n",
            "  1.76125243e-02 1.95694715e-02 4.01174158e-01 4.50097844e-02]\n",
            " [2.02427700e-01 3.57015361e-03 1.42806144e-02 3.51660132e-01\n",
            "  2.60621198e-02 1.84219927e-01 3.53445187e-02 3.57015361e-03\n",
            "  1.42806140e-03 3.74866128e-02 2.07068902e-02 1.19243130e-01]\n",
            " [2.09708735e-02 5.24271838e-03 1.68932043e-02 6.96893215e-01\n",
            "  1.14563107e-02 2.17475723e-02 6.33009672e-02 5.24271838e-03\n",
            "  1.94174761e-04 8.05825219e-02 1.14563107e-02 6.60194159e-02]\n",
            " [2.28859577e-02 7.13731572e-02 6.98215654e-03 3.21955010e-02\n",
            "  1.47401085e-02 2.98681147e-02 1.30721495e-01 8.14584941e-02\n",
            "  1.20248254e-02 1.19472459e-01 3.39022487e-01 1.39255241e-01]\n",
            " [8.83826911e-02 9.56719834e-03 5.01138950e-03 2.12756261e-01\n",
            "  1.41230067e-02 6.83371304e-03 7.06150308e-02 3.69020514e-02\n",
            "  6.83371304e-03 2.23234631e-02 4.84738052e-01 4.19134386e-02]\n",
            " [3.45482156e-02 3.20931405e-01 1.01240189e-03 3.23588967e-01\n",
            "  1.26550242e-03 6.32751212e-02 1.07061505e-01 1.45532778e-02\n",
            "  6.96026310e-02 1.69577319e-02 8.47886596e-03 3.87243740e-02]\n",
            " [2.15930015e-01 1.33609578e-01 5.43278083e-03 1.10589318e-01\n",
            "  3.06629837e-02 2.28360966e-02 6.63904250e-02 8.38858187e-02\n",
            "  3.55432779e-02 9.23572779e-02 1.67955801e-01 3.48066315e-02]\n",
            " [2.56410260e-02 1.72191828e-01 6.00793920e-02 2.18538776e-01\n",
            "  2.78940029e-03 7.82104954e-02 4.61323895e-02 5.25694676e-02\n",
            "  6.87694475e-02 9.29084867e-02 8.96899477e-02 9.23720598e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "Bfood3ZJsCr4",
        "outputId": "fb305c86-285d-4669-f4c9-d63e628381f2"
      },
      "source": [
        "# convert the matrix to a df for better readability\n",
        "#the table is same as the transition table shown in section 3 of article\n",
        "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
        "display(tags_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>DET</th>\n",
              "      <th>CONJ</th>\n",
              "      <th>NOUN</th>\n",
              "      <th>PRT</th>\n",
              "      <th>NUM</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>ADV</th>\n",
              "      <th>PRON</th>\n",
              "      <th>ADP</th>\n",
              "      <th>VERB</th>\n",
              "      <th>.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <td>0.075726</td>\n",
              "      <td>0.056890</td>\n",
              "      <td>0.010379</td>\n",
              "      <td>0.061695</td>\n",
              "      <td>0.185086</td>\n",
              "      <td>0.003075</td>\n",
              "      <td>0.017682</td>\n",
              "      <td>0.025754</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>0.142226</td>\n",
              "      <td>0.206419</td>\n",
              "      <td>0.160869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DET</th>\n",
              "      <td>0.045134</td>\n",
              "      <td>0.006037</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>0.635906</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.022855</td>\n",
              "      <td>0.206411</td>\n",
              "      <td>0.012074</td>\n",
              "      <td>0.003306</td>\n",
              "      <td>0.009918</td>\n",
              "      <td>0.040247</td>\n",
              "      <td>0.017393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONJ</th>\n",
              "      <td>0.009330</td>\n",
              "      <td>0.123491</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.349067</td>\n",
              "      <td>0.004391</td>\n",
              "      <td>0.040615</td>\n",
              "      <td>0.113611</td>\n",
              "      <td>0.057080</td>\n",
              "      <td>0.060373</td>\n",
              "      <td>0.055982</td>\n",
              "      <td>0.150384</td>\n",
              "      <td>0.035126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOUN</th>\n",
              "      <td>0.028825</td>\n",
              "      <td>0.013106</td>\n",
              "      <td>0.042454</td>\n",
              "      <td>0.262344</td>\n",
              "      <td>0.043935</td>\n",
              "      <td>0.009144</td>\n",
              "      <td>0.012584</td>\n",
              "      <td>0.016895</td>\n",
              "      <td>0.004659</td>\n",
              "      <td>0.176827</td>\n",
              "      <td>0.149134</td>\n",
              "      <td>0.240094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRT</th>\n",
              "      <td>0.012133</td>\n",
              "      <td>0.101370</td>\n",
              "      <td>0.002348</td>\n",
              "      <td>0.250489</td>\n",
              "      <td>0.001174</td>\n",
              "      <td>0.056751</td>\n",
              "      <td>0.082975</td>\n",
              "      <td>0.009393</td>\n",
              "      <td>0.017613</td>\n",
              "      <td>0.019569</td>\n",
              "      <td>0.401174</td>\n",
              "      <td>0.045010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM</th>\n",
              "      <td>0.202428</td>\n",
              "      <td>0.003570</td>\n",
              "      <td>0.014281</td>\n",
              "      <td>0.351660</td>\n",
              "      <td>0.026062</td>\n",
              "      <td>0.184220</td>\n",
              "      <td>0.035345</td>\n",
              "      <td>0.003570</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>0.037487</td>\n",
              "      <td>0.020707</td>\n",
              "      <td>0.119243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADJ</th>\n",
              "      <td>0.020971</td>\n",
              "      <td>0.005243</td>\n",
              "      <td>0.016893</td>\n",
              "      <td>0.696893</td>\n",
              "      <td>0.011456</td>\n",
              "      <td>0.021748</td>\n",
              "      <td>0.063301</td>\n",
              "      <td>0.005243</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.080583</td>\n",
              "      <td>0.011456</td>\n",
              "      <td>0.066019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADV</th>\n",
              "      <td>0.022886</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.006982</td>\n",
              "      <td>0.032196</td>\n",
              "      <td>0.014740</td>\n",
              "      <td>0.029868</td>\n",
              "      <td>0.130721</td>\n",
              "      <td>0.081458</td>\n",
              "      <td>0.012025</td>\n",
              "      <td>0.119472</td>\n",
              "      <td>0.339022</td>\n",
              "      <td>0.139255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRON</th>\n",
              "      <td>0.088383</td>\n",
              "      <td>0.009567</td>\n",
              "      <td>0.005011</td>\n",
              "      <td>0.212756</td>\n",
              "      <td>0.014123</td>\n",
              "      <td>0.006834</td>\n",
              "      <td>0.070615</td>\n",
              "      <td>0.036902</td>\n",
              "      <td>0.006834</td>\n",
              "      <td>0.022323</td>\n",
              "      <td>0.484738</td>\n",
              "      <td>0.041913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADP</th>\n",
              "      <td>0.034548</td>\n",
              "      <td>0.320931</td>\n",
              "      <td>0.001012</td>\n",
              "      <td>0.323589</td>\n",
              "      <td>0.001266</td>\n",
              "      <td>0.063275</td>\n",
              "      <td>0.107062</td>\n",
              "      <td>0.014553</td>\n",
              "      <td>0.069603</td>\n",
              "      <td>0.016958</td>\n",
              "      <td>0.008479</td>\n",
              "      <td>0.038724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VERB</th>\n",
              "      <td>0.215930</td>\n",
              "      <td>0.133610</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.110589</td>\n",
              "      <td>0.030663</td>\n",
              "      <td>0.022836</td>\n",
              "      <td>0.066390</td>\n",
              "      <td>0.083886</td>\n",
              "      <td>0.035543</td>\n",
              "      <td>0.092357</td>\n",
              "      <td>0.167956</td>\n",
              "      <td>0.034807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.172192</td>\n",
              "      <td>0.060079</td>\n",
              "      <td>0.218539</td>\n",
              "      <td>0.002789</td>\n",
              "      <td>0.078210</td>\n",
              "      <td>0.046132</td>\n",
              "      <td>0.052569</td>\n",
              "      <td>0.068769</td>\n",
              "      <td>0.092908</td>\n",
              "      <td>0.089690</td>\n",
              "      <td>0.092372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             X       DET      CONJ  ...       ADP      VERB         .\n",
              "X     0.075726  0.056890  0.010379  ...  0.142226  0.206419  0.160869\n",
              "DET   0.045134  0.006037  0.000431  ...  0.009918  0.040247  0.017393\n",
              "CONJ  0.009330  0.123491  0.000549  ...  0.055982  0.150384  0.035126\n",
              "NOUN  0.028825  0.013106  0.042454  ...  0.176827  0.149134  0.240094\n",
              "PRT   0.012133  0.101370  0.002348  ...  0.019569  0.401174  0.045010\n",
              "NUM   0.202428  0.003570  0.014281  ...  0.037487  0.020707  0.119243\n",
              "ADJ   0.020971  0.005243  0.016893  ...  0.080583  0.011456  0.066019\n",
              "ADV   0.022886  0.071373  0.006982  ...  0.119472  0.339022  0.139255\n",
              "PRON  0.088383  0.009567  0.005011  ...  0.022323  0.484738  0.041913\n",
              "ADP   0.034548  0.320931  0.001012  ...  0.016958  0.008479  0.038724\n",
              "VERB  0.215930  0.133610  0.005433  ...  0.092357  0.167956  0.034807\n",
              ".     0.025641  0.172192  0.060079  ...  0.092908  0.089690  0.092372\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKArNy5tsE9Q"
      },
      "source": [
        "def Viterbi(words, train_bag = train_tagged_words):\n",
        "    state = []\n",
        "    T = list(set([pair[1] for pair in train_bag]))\n",
        "     \n",
        "    for key, word in enumerate(words):\n",
        "        #initialise list of probability column for a given observation\n",
        "        p = [] \n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[state[-1], tag]\n",
        "                 \n",
        "            # compute emission and state probabilities\n",
        "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
        "            state_probability = emission_p * transition_p    \n",
        "            p.append(state_probability)\n",
        "             \n",
        "        pmax = max(p)\n",
        "        # getting state for which probability is maximum\n",
        "        state_max = T[p.index(pmax)] \n",
        "        state.append(state_max)\n",
        "    return list(zip(words, state))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPWzXX5tsG97"
      },
      "source": [
        "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
        "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
        " \n",
        "# choose random 10 numbers\n",
        "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
        " \n",
        "# list of 10 sents on which we test the model\n",
        "test_run = [test_set[i] for i in rndom]\n",
        " \n",
        "# list of tagged words\n",
        "test_run_base = [tup for sent in test_run for tup in sent]\n",
        " \n",
        "# list of untagged words\n",
        "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVc36SVksIyX",
        "outputId": "7221fefc-ace2-4bbd-bfc2-690ff4267dd5"
      },
      "source": [
        "#Here We will only test 10 sentences to check the accuracy\n",
        "#as testing the whole training set takes huge amount of time\n",
        "start = time.time()\n",
        "tagged_seq = Viterbi(test_tagged_words)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        " \n",
        "print(\"Time taken in seconds: \", difference)\n",
        " \n",
        "# accuracy\n",
        "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
        " \n",
        "accuracy = len(check)/len(tagged_seq)\n",
        "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken in seconds:  39.675126791000366\n",
            "Viterbi Algorithm Accuracy:  94.25837320574163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2ij9RzzsKr3"
      },
      "source": [
        "#To improve the performance,we specify a rule base tagger for unknown words \n",
        "# specify patterns for tagging\n",
        "patterns = [\n",
        "    (r'.*ing$', 'VERB'),              # gerund\n",
        "    (r'.*ed$', 'VERB'),               # past tense \n",
        "    (r'.*es$', 'VERB'),               # verb    \n",
        "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
        "    (r'.*s$', 'NOUN'),                # plural nouns\n",
        "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
        "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
        "    (r'.*', 'NOUN')                   # nouns\n",
        "]\n",
        " \n",
        "# rule based tagger\n",
        "rule_based_tagger = nltk.RegexpTagger(patterns)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewWtbw5isM9H"
      },
      "source": [
        "#modified Viterbi to include rule based tagger in it\n",
        "def Viterbi_rule_based(words, train_bag = train_tagged_words):\n",
        "    state = []\n",
        "    T = list(set([pair[1] for pair in train_bag]))\n",
        "     \n",
        "    for key, word in enumerate(words):\n",
        "        #initialise list of probability column for a given observation\n",
        "        p = [] \n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[state[-1], tag]\n",
        "                 \n",
        "            # compute emission and state probabilities\n",
        "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
        "            state_probability = emission_p * transition_p    \n",
        "            p.append(state_probability)\n",
        "             \n",
        "        pmax = max(p)\n",
        "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
        "        \n",
        "         \n",
        "        if(pmax==0):\n",
        "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
        "        else:\n",
        "            if state_max != 'X':\n",
        "                # getting state for which probability is maximum\n",
        "                state_max = T[p.index(pmax)]                \n",
        "             \n",
        "         \n",
        "        state.append(state_max)\n",
        "    return list(zip(words, state))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO_YxitFsQ2j",
        "outputId": "7ba2ceb7-74dc-423d-f501-20aab2294271"
      },
      "source": [
        "#test accuracy on subset of test data \n",
        "start = time.time()\n",
        "tagged_seq = Viterbi_rule_based(test_tagged_words)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        " \n",
        "print(\"Time taken in seconds: \", difference)\n",
        " \n",
        "# accuracy\n",
        "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
        " \n",
        "accuracy = len(check)/len(tagged_seq)\n",
        "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken in seconds:  39.2841374874115\n",
            "Viterbi Algorithm Accuracy:  97.1291866028708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x45KTdMsSqD",
        "outputId": "a6bafd8d-9f27-4a30-f062-2b7bbbb3e2e5"
      },
      "source": [
        "#Check how a sentence is tagged by the two POS taggers\n",
        "#and compare them\n",
        "test_sent=\"Booking a Train Ticket\"\n",
        "pred_tags_rule=Viterbi_rule_based(test_sent.split())\n",
        "pred_tags_withoutRules= Viterbi(test_sent.split())\n",
        "print(pred_tags_rule)\n",
        "print(pred_tags_withoutRules)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Booking', 'VERB'), ('a', 'DET'), ('Train', 'NOUN'), ('Ticket', 'NOUN')]\n",
            "[('Booking', 'X'), ('a', 'DET'), ('Train', 'X'), ('Ticket', 'X')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIWlyk2sUlb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}