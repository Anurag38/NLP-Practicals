{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5R0keS87wnF23+NVVyY3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anurag38/NLP-Practicals/blob/main/Practical%204%20-%20word2vec/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV9yBdmqjdJw"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.wrappers import FastText\n",
        "from gensim.models import FastText\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZgP_cbcjdJ8"
      },
      "source": [
        "import itertools\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "#from glove import Corpus, Glove\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "# from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "#from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4mzkpFjdKC"
      },
      "source": [
        "# provide sql-like data manipulation tools. very handy.\n",
        "import pandas as pd \n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# high dimensional vector computing library.\n",
        "import numpy as np \n",
        "from copy import deepcopy\n",
        "from string import punctuation\n",
        "from random import shuffle\n",
        "\n",
        "import gensim\n",
        "\n",
        "# the word2vec model gensim class\n",
        "from gensim.models.word2vec import Word2Vec \n",
        "\n",
        "# we'll talk about this down below\n",
        "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "\n",
        "# a tweet tokenizer from nltk.\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJlK_bclxRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d32d55d-4f3d-45c4-ccd0-d94ce3e563e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bapfnCCwjdKF"
      },
      "source": [
        "train= pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/AMI/dataset/taska.txt',header=None,sep='\\t',names=['id','text','class'])\n",
        "#valid_df= pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/AMI/dataset/agr_en_dev.csv',header=None,names=['id','text','class'])\n",
        "\n",
        "#test_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/AMI/dataset/agr_en_fb_gold.csv',header=None,names=['id','text','class'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQbm7GAUu56L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffe56e2-5abc-4cff-9d50-5e44d7a59cb4"
      },
      "source": [
        "train.info()\n",
        "train.head()\n",
        "train['class'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13240 entries, 0 to 13239\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      13240 non-null  int64 \n",
            " 1   text    13240 non-null  object\n",
            " 2   class   13240 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 310.4+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOT    8840\n",
              "OFF    4400\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsyPoHQmjdKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fcd2263d-bc4a-4e0e-9d23-99f9896cc809"
      },
      "source": [
        "import re\n",
        "def clean_text(comment):\n",
        "    comment = comment.strip().strip('\"')\n",
        "    comment = comment.replace('_', ' ')\n",
        "    comment = comment.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "    comment = comment.replace('\\\\n', ' ')\n",
        "    comment = comment.replace('\\\\n', ' ')\n",
        "    comment = comment.lower()\n",
        "    comment = re.sub(r'@[A-Za-z0-9]+','',comment)\n",
        "    \n",
        "    comment = re.sub('https?://[A-Za-z0-9./]+','',comment)\n",
        "    commment = re.sub(\"[^a-zA-Z]\", \" \", comment)\n",
        "    comment = re.sub(r'[^\\w\\s]','',comment)\n",
        "\n",
        "    \n",
        "    return comment\n",
        "\n",
        "train['text'] = train['text'].fillna(\"something\").values\n",
        "train['ctext']=train['text'].apply(clean_text)\n",
        "#train_df['ctext']=train_df['text']\n",
        "#valid_df['ctext']=valid_df['text'].apply(clean_text)\n",
        "#test_df['ctext']=test_df['text'].apply(clean_text)\n",
        "train.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>go home youre drunk  maga trump2020  url</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>obama wanted liberals amp illegals to move i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                              ctext\n",
              "0  86426  ...   she should ask a few native americans what th...\n",
              "1  90194  ...           go home youre drunk  maga trump2020  url\n",
              "2  16820  ...  amazon is investigating chinese employees who ...\n",
              "3  62688  ...   someone shouldvetaken this piece of shit to a...\n",
              "4  43605  ...    obama wanted liberals amp illegals to move i...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfFib4IVzhMa"
      },
      "source": [
        "#tr=train_df[train_df['text']=='something']\n",
        "#tr.head()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSZtRWUEjdKL"
      },
      "source": [
        "#train_df['text'] = train_df['text'].fillna(\"something\").values\n",
        "train['class'] = train['class'].map({'OFF': 0, 'NOT': 1})\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYRwceo6-qsL"
      },
      "source": [
        "train_df, test_df = train_test_split(train,test_size = 0.1)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-LT_MCQjdKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa61f6a3-82ff-4e0e-ddb5-f7dcc91b8934"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "train_df['tokenized_sents'] = train_df.apply(lambda row: nltk.word_tokenize(row['ctext']), axis=1)\n",
        "test_df['tokenized_sents'] = test_df.apply(lambda row: nltk.word_tokenize(row['ctext']), axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4wHg32CZAgdS",
        "outputId": "d1c4902f-4702-4b78-991c-17ed88795301"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>ctext</th>\n",
              "      <th>tokenized_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7125</th>\n",
              "      <td>68984</td>\n",
              "      <td>@USER But you are? Give me a break!</td>\n",
              "      <td>1</td>\n",
              "      <td>but you are give me a break</td>\n",
              "      <td>[but, you, are, give, me, a, break]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12144</th>\n",
              "      <td>87051</td>\n",
              "      <td>@USER @USER @USER @USER Don't feel sorry for h...</td>\n",
              "      <td>0</td>\n",
              "      <td>dont feel sorry for her she is so greedy s...</td>\n",
              "      <td>[dont, feel, sorry, for, her, she, is, so, gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4283</th>\n",
              "      <td>62703</td>\n",
              "      <td>@USER Arrest everyone of them! We should be do...</td>\n",
              "      <td>1</td>\n",
              "      <td>arrest everyone of them we should be doing th...</td>\n",
              "      <td>[arrest, everyone, of, them, we, should, be, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12083</th>\n",
              "      <td>42482</td>\n",
              "      <td>10 restaurant diners fatally shot in Corpus Ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>10 restaurant diners fatally shot in corpus ch...</td>\n",
              "      <td>[10, restaurant, diners, fatally, shot, in, co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3287</th>\n",
              "      <td>86117</td>\n",
              "      <td>@USER You are the man Gregg!</td>\n",
              "      <td>1</td>\n",
              "      <td>you are the man gregg</td>\n",
              "      <td>[you, are, the, man, gregg]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                    tokenized_sents\n",
              "7125   68984  ...                [but, you, are, give, me, a, break]\n",
              "12144  87051  ...  [dont, feel, sorry, for, her, she, is, so, gre...\n",
              "4283   62703  ...  [arrest, everyone, of, them, we, should, be, d...\n",
              "12083  42482  ...  [10, restaurant, diners, fatally, shot, in, co...\n",
              "3287   86117  ...                        [you, are, the, man, gregg]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FkdPexWjdKQ"
      },
      "source": [
        "x_train=train_df['tokenized_sents']\n",
        "x_test=test_df['tokenized_sents']\n",
        "\n",
        "y_train=train_df['class']\n",
        "y_test=test_df['class']\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PytDaKaMjdKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799273a8-c2bb-461b-dd3c-6c8d8e833701"
      },
      "source": [
        "def labelizeTweets(tweets, label_type):\n",
        "    labelized = []\n",
        "    for i,v in tqdm(enumerate(tweets)):\n",
        "        label = '%s_%s'%(label_type,i)\n",
        "        labelized.append(LabeledSentence(v, [label]))\n",
        "    return labelized\n",
        "\n",
        "x_train = labelizeTweets(x_train, 'TRAIN')\n",
        "\n",
        "x_test = labelizeTweets(x_test, 'TEST')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  \"\"\"\n",
            "11916it [00:00, 243843.22it/s]\n",
            "1324it [00:00, 7077.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZoOxMHjdKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa97a5e-d4d4-4e8b-9849-28b010f2f29f"
      },
      "source": [
        "#tweet_w2v = FastText(size=400, min_count=1,sg=1)\n",
        "tweet_w2v = Word2Vec(size=300, min_count=1,sg=1) #SKIPGRAM\n",
        "tweet_w2v.build_vocab([x.words for x in tqdm(x_train)])\n",
        "tweet_w2v.train([x.words for x in tqdm(x_train)],total_examples=len(x_train),epochs=10)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11916/11916 [00:00<00:00, 1250859.11it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11916/11916 [00:00<00:00, 1540242.43it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1818227, 2334250)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_42crwv7-6x",
        "outputId": "20659ecb-765e-4c09-a3dd-7cfb77b40e8e"
      },
      "source": [
        "tweet_w2v['hello']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0678657 ,  0.14923333,  0.05878469,  0.05446722, -0.10443438,\n",
              "       -0.13105269, -0.13153464,  0.0372822 , -0.01119888, -0.00892492,\n",
              "       -0.07212088, -0.02818428, -0.04634731, -0.05089912, -0.07144504,\n",
              "        0.01041827, -0.09932423,  0.08100637, -0.32556817,  0.01157103,\n",
              "        0.0879048 ,  0.00543198, -0.08159877, -0.01675915, -0.06183286,\n",
              "       -0.14255397, -0.07467941,  0.12077925, -0.05880748, -0.08940005,\n",
              "       -0.08674736, -0.17640902,  0.1004069 ,  0.06550197, -0.15900809,\n",
              "       -0.02836237, -0.00280109, -0.00492049, -0.10798977, -0.14996919,\n",
              "        0.14022781,  0.0088025 ,  0.18589672,  0.09244545,  0.00438946,\n",
              "        0.00231881,  0.06667206,  0.07980375,  0.12325242, -0.05567688,\n",
              "       -0.02295933,  0.07490967,  0.02445438, -0.10410339,  0.0064341 ,\n",
              "        0.2402889 , -0.10417822,  0.1718549 , -0.2294985 ,  0.00942066,\n",
              "        0.06131065, -0.03393849, -0.13653105,  0.07537535,  0.04390161,\n",
              "       -0.06119368, -0.1598253 , -0.0900723 ,  0.10706846,  0.03648941,\n",
              "       -0.0851883 ,  0.04542561,  0.00060107, -0.04407839,  0.07029226,\n",
              "       -0.05752475,  0.20478383, -0.06236318,  0.03468996, -0.00287481,\n",
              "       -0.03048136,  0.13719244,  0.1221638 , -0.02368689,  0.00043259,\n",
              "       -0.00632696, -0.03997457,  0.00914781,  0.04144369, -0.15691824,\n",
              "        0.04912207,  0.15568724, -0.06356015, -0.00260821,  0.02572078,\n",
              "        0.03682077, -0.13352886, -0.06839966,  0.06455974, -0.14472431,\n",
              "       -0.01723623,  0.0058775 ,  0.09025186, -0.15484892,  0.22310655,\n",
              "        0.01041172,  0.11899901, -0.00160652,  0.01410002,  0.00949024,\n",
              "       -0.0593152 ,  0.07479461, -0.06352942, -0.08817351,  0.0352378 ,\n",
              "       -0.15436421, -0.03898124, -0.0997357 , -0.07754377,  0.02365529,\n",
              "        0.07019366,  0.05003744, -0.07022785,  0.26624477, -0.03632736,\n",
              "       -0.02549119,  0.1510324 , -0.00483883, -0.07398786, -0.06805464,\n",
              "       -0.02583064, -0.00683363,  0.00610409, -0.07891351, -0.03081538,\n",
              "        0.02287428, -0.23295487,  0.10098235, -0.12248008, -0.10888408,\n",
              "        0.1249456 ,  0.12210759, -0.03195077,  0.01167322, -0.04903681,\n",
              "        0.09413872, -0.012713  , -0.17104258, -0.30481786, -0.15168792,\n",
              "        0.06770872,  0.08881389,  0.0121514 , -0.0939952 , -0.13121174,\n",
              "       -0.16979599,  0.14954929,  0.07247236,  0.17513494, -0.04104451,\n",
              "       -0.05119934,  0.17240345,  0.07625709,  0.12048085, -0.06342002,\n",
              "       -0.00919387, -0.0453004 , -0.01429139, -0.02504922, -0.03052775,\n",
              "        0.05321721, -0.09817467, -0.15093634, -0.01801264, -0.01040078,\n",
              "        0.05684499,  0.1063524 ,  0.01551109,  0.09111803, -0.0779394 ,\n",
              "       -0.00746464, -0.08152664,  0.25000623, -0.0540472 ,  0.05261639,\n",
              "       -0.12795226, -0.06898047, -0.04422943,  0.09381766, -0.17564376,\n",
              "       -0.19433112,  0.10801239, -0.06323184, -0.11245369,  0.04529583,\n",
              "        0.02447508,  0.06234549,  0.15393898,  0.08988   ,  0.00532301,\n",
              "       -0.02114518,  0.05505056,  0.20919631,  0.01241227,  0.18784726,\n",
              "        0.23894092, -0.03726657,  0.02126823, -0.13365322,  0.12138276,\n",
              "        0.07128478, -0.05305024,  0.05855113, -0.24271163,  0.0239231 ,\n",
              "       -0.06165898, -0.14763166,  0.0474064 ,  0.18860275, -0.00610486,\n",
              "       -0.1195678 ,  0.14162827,  0.02565463,  0.1383024 ,  0.04912413,\n",
              "       -0.0776096 ,  0.08343361,  0.27243888, -0.02570467,  0.04706046,\n",
              "       -0.07780842,  0.00839495,  0.0781055 ,  0.00374832,  0.03489093,\n",
              "       -0.00824795, -0.03185175, -0.04964389,  0.13093904, -0.04405359,\n",
              "        0.04604021, -0.09128287, -0.03949763, -0.0081931 ,  0.01451264,\n",
              "       -0.00821834,  0.00149492,  0.15461405,  0.0264022 ,  0.01078462,\n",
              "       -0.07485859, -0.10889547, -0.2986019 , -0.06055236, -0.07029436,\n",
              "       -0.124271  ,  0.00901238,  0.08957595, -0.03764212, -0.04842765,\n",
              "        0.15604493, -0.01211613,  0.07819954,  0.09045618,  0.01517812,\n",
              "        0.04064444,  0.15814625,  0.08863093,  0.09003154, -0.07240302,\n",
              "        0.0445797 , -0.09129447, -0.19376482,  0.01658587, -0.16213164,\n",
              "       -0.09975511,  0.0538446 ,  0.05491363,  0.08197606, -0.1451471 ,\n",
              "       -0.02894799,  0.06851604, -0.0257919 ,  0.10464093, -0.03616428,\n",
              "        0.00576655,  0.11604639,  0.0600889 ,  0.05365686,  0.16484103,\n",
              "       -0.03345719,  0.17660049, -0.10149601,  0.06666667, -0.14412488,\n",
              "        0.03149375, -0.06897   ,  0.29322556, -0.13259937,  0.03872448],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "LZtGGuve724c",
        "outputId": "74d2d9d4-3af2-4c56-c264-4fa40fa803e8"
      },
      "source": [
        "tweet_w2v['anurag']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-12ffe7e0ca66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_w2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anurag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 )\n\u001b[0;32m-> 1422\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'anurag' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lku_BDNEjdKb"
      },
      "source": [
        "#tweet_w2v.save('off-sg.vec')\n",
        "#tweet_w2v.save('fb-en-w2vec-cbow.bin')\n",
        "#tweet_w2v.wv.save_word2vec_format('fb-hi-w2vec-cbow.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}