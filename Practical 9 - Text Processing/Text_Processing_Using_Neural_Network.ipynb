{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Processing Using Neural Network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNY36r+opCvCe/689uDxwle",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anurag38/NLP-Practicals/blob/main/Practical%209%20-%20Text%20Processing/Text_Processing_Using_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV9yBdmqjdJw"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.wrappers import FastText\n",
        "from gensim.models import FastText\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZgP_cbcjdJ8"
      },
      "source": [
        "import itertools\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "#from glove import Corpus, Glove\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "# from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "#from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4mzkpFjdKC"
      },
      "source": [
        "# provide sql-like data manipulation tools. very handy.\n",
        "import pandas as pd \n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# high dimensional vector computing library.\n",
        "import numpy as np \n",
        "from copy import deepcopy\n",
        "from string import punctuation\n",
        "from random import shuffle\n",
        "\n",
        "import gensim\n",
        "\n",
        "# the word2vec model gensim class\n",
        "from gensim.models.word2vec import Word2Vec \n",
        "\n",
        "# we'll talk about this down below\n",
        "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "\n",
        "# a tweet tokenizer from nltk.\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJlK_bclxRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a607759-9aca-451f-8beb-00629c3dbf6e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bapfnCCwjdKF"
      },
      "source": [
        "train= pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/NLP/Practical 9/taska.txt',header=None,sep='\\t',names=['id','text','class'])\n",
        "#valid_df= pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/AMI/dataset/agr_en_dev.csv',header=None,names=['id','text','class'])\n",
        "\n",
        "#test_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/AMI/dataset/agr_en_fb_gold.csv',header=None,names=['id','text','class'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQbm7GAUu56L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac1a4e2-e154-4e4b-adbb-18b1681cd785"
      },
      "source": [
        "train.info()\n",
        "train.head()\n",
        "train['class'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13240 entries, 0 to 13239\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      13240 non-null  int64 \n",
            " 1   text    13240 non-null  object\n",
            " 2   class   13240 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 310.4+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOT    8840\n",
              "OFF    4400\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsyPoHQmjdKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3c4fc7f5-e71d-4ab9-8191-50ed3760742f"
      },
      "source": [
        "import re\n",
        "def clean_text(comment):\n",
        "    comment = comment.strip().strip('\"')\n",
        "    comment = comment.replace('_', ' ')\n",
        "    comment = comment.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "    comment = comment.replace('\\\\n', ' ')\n",
        "    comment = comment.replace('\\\\n', ' ')\n",
        "    comment = comment.lower()\n",
        "    comment = re.sub(r'@[A-Za-z0-9]+','',comment)\n",
        "    \n",
        "    comment = re.sub('https?://[A-Za-z0-9./]+','',comment)\n",
        "    commment = re.sub(\"[^a-zA-Z]\", \" \", comment)\n",
        "    comment = re.sub(r'[^\\w\\s]','',comment)\n",
        "\n",
        "    \n",
        "    return comment\n",
        "\n",
        "train['text'] = train['text'].fillna(\"something\").values\n",
        "train['ctext']=train['text'].apply(clean_text)\n",
        "#train_df['ctext']=train_df['text']\n",
        "#valid_df['ctext']=valid_df['text'].apply(clean_text)\n",
        "#test_df['ctext']=test_df['text'].apply(clean_text)\n",
        "train.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>she should ask a few native americans what th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>go home youre drunk  maga trump2020  url</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>someone shouldvetaken this piece of shit to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>obama wanted liberals amp illegals to move i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                              ctext\n",
              "0  86426  ...   she should ask a few native americans what th...\n",
              "1  90194  ...           go home youre drunk  maga trump2020  url\n",
              "2  16820  ...  amazon is investigating chinese employees who ...\n",
              "3  62688  ...   someone shouldvetaken this piece of shit to a...\n",
              "4  43605  ...    obama wanted liberals amp illegals to move i...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfFib4IVzhMa"
      },
      "source": [
        "#tr=train_df[train_df['text']=='something']\n",
        "#tr.head()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSZtRWUEjdKL"
      },
      "source": [
        "#train_df['text'] = train_df['text'].fillna(\"something\").values\n",
        "train['class'] = train['class'].map({'OFF': 0, 'NOT': 1})\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYRwceo6-qsL"
      },
      "source": [
        "train_df, test_df = train_test_split(train,test_size = 0.1)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-LT_MCQjdKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad34af8e-7a75-4e38-ab22-f8b13115c8be"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "train_df['tokenized_sents'] = train_df.apply(lambda row: nltk.word_tokenize(row['ctext']), axis=1)\n",
        "test_df['tokenized_sents'] = test_df.apply(lambda row: nltk.word_tokenize(row['ctext']), axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4wHg32CZAgdS",
        "outputId": "8a35a1ea-ef98-4b85-c71e-646260cffa3f"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>ctext</th>\n",
              "      <th>tokenized_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10099</th>\n",
              "      <td>40731</td>\n",
              "      <td>@USER fuck yeah !</td>\n",
              "      <td>0</td>\n",
              "      <td>fuck yeah</td>\n",
              "      <td>[fuck, yeah]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6109</th>\n",
              "      <td>10009</td>\n",
              "      <td>@USER @USER @USER @USER Did you attend Governo...</td>\n",
              "      <td>0</td>\n",
              "      <td>did you attend governor abbotts meetings o...</td>\n",
              "      <td>[did, you, attend, governor, abbotts, meetings...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8411</th>\n",
              "      <td>85315</td>\n",
              "      <td>@USER @USER Sloppy and pathetic.</td>\n",
              "      <td>1</td>\n",
              "      <td>sloppy and pathetic</td>\n",
              "      <td>[sloppy, and, pathetic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9048</th>\n",
              "      <td>38056</td>\n",
              "      <td>@USER @USER @USER @USER Read @USER that I just...</td>\n",
              "      <td>1</td>\n",
              "      <td>read  that i just posted he got too close ...</td>\n",
              "      <td>[read, that, i, just, posted, he, got, too, cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8149</th>\n",
              "      <td>58969</td>\n",
              "      <td>@USER Real victims of sexual assault/harassmen...</td>\n",
              "      <td>1</td>\n",
              "      <td>real victims of sexual assaultharassment see ...</td>\n",
              "      <td>[real, victims, of, sexual, assaultharassment,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                    tokenized_sents\n",
              "10099  40731  ...                                       [fuck, yeah]\n",
              "6109   10009  ...  [did, you, attend, governor, abbotts, meetings...\n",
              "8411   85315  ...                            [sloppy, and, pathetic]\n",
              "9048   38056  ...  [read, that, i, just, posted, he, got, too, cl...\n",
              "8149   58969  ...  [real, victims, of, sexual, assaultharassment,...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FkdPexWjdKQ"
      },
      "source": [
        "x_train=train_df['tokenized_sents']\n",
        "x_test=test_df['tokenized_sents']\n",
        "\n",
        "y_train=train_df['class']\n",
        "y_test=test_df['class']\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PytDaKaMjdKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da4ee24-bdc2-491b-e4cf-615e0053ac3f"
      },
      "source": [
        "def labelizeTweets(tweets, label_type):\n",
        "    labelized = []\n",
        "    for i,v in tqdm(enumerate(tweets)):\n",
        "        label = '%s_%s'%(label_type,i)\n",
        "        labelized.append(LabeledSentence(v, [label]))\n",
        "    return labelized\n",
        "\n",
        "x_train = labelizeTweets(x_train, 'TRAIN')\n",
        "\n",
        "x_test = labelizeTweets(x_test, 'TEST')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  \"\"\"\n",
            "11916it [00:00, 164447.87it/s]\n",
            "1324it [00:00, 7812.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZoOxMHjdKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cc120e-383d-4285-e801-0dd6abfb012e"
      },
      "source": [
        "#tweet_w2v = FastText(size=400, min_count=1,sg=1)\n",
        "tweet_w2v = Word2Vec(size=300, min_count=1,sg=1) #SKIPGRAM\n",
        "tweet_w2v.build_vocab([x.words for x in tqdm(x_train)])\n",
        "tweet_w2v.train([x.words for x in tqdm(x_train)],total_examples=len(x_train),epochs=10)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11916/11916 [00:00<00:00, 1776979.54it/s]\n",
            "100%|██████████| 11916/11916 [00:00<00:00, 1659505.48it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1817689, 2333720)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_42crwv7-6x",
        "outputId": "08175dfe-4caa-42da-a981-59fda141797a"
      },
      "source": [
        "tweet_w2v['hello']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0245385 ,  0.01042343,  0.07029286, -0.08592399, -0.00728595,\n",
              "        0.05229944, -0.08987518, -0.01976275,  0.05312984,  0.07454742,\n",
              "       -0.00459528, -0.07464006,  0.13708974,  0.01855008, -0.04661439,\n",
              "       -0.05090912, -0.15324254, -0.05939812,  0.13873217, -0.20823406,\n",
              "        0.06541061, -0.10304102, -0.00307648,  0.01553386,  0.04710938,\n",
              "       -0.04464864,  0.03309749, -0.04163473, -0.05369332,  0.07051885,\n",
              "        0.01935233, -0.00962516,  0.00170115, -0.11199442, -0.14744046,\n",
              "        0.02202365, -0.13418731, -0.02419685, -0.07234977,  0.03682282,\n",
              "        0.07348078,  0.2031062 ,  0.0991015 , -0.01744791, -0.0072599 ,\n",
              "       -0.20430917,  0.09818937,  0.11944608,  0.07149309,  0.16775118,\n",
              "        0.0611512 , -0.09724732, -0.08685201, -0.08746489,  0.10104701,\n",
              "        0.04837935, -0.01504948,  0.0680185 , -0.02765145,  0.08062874,\n",
              "       -0.04698613, -0.03928098,  0.00120092, -0.10226735,  0.14784406,\n",
              "        0.05963786, -0.08266125, -0.11659907,  0.05641096,  0.13693061,\n",
              "        0.00802395, -0.07093953, -0.12976685,  0.13257009, -0.15178308,\n",
              "        0.02836579,  0.01058885,  0.02677818,  0.09904741,  0.16912623,\n",
              "        0.16118154,  0.15008517,  0.07103423, -0.06034213,  0.07020638,\n",
              "        0.03279666,  0.04175434, -0.1848971 , -0.05130213,  0.07335762,\n",
              "       -0.08842734, -0.03037383, -0.00714861,  0.02901813, -0.04776844,\n",
              "       -0.00130777,  0.15251224, -0.01943762,  0.01590681,  0.05619608,\n",
              "        0.05351896, -0.09839751,  0.14798516,  0.06704447,  0.07918041,\n",
              "        0.18341817, -0.09399053,  0.18282735,  0.1324707 , -0.01560843,\n",
              "        0.02970372, -0.03077652, -0.00505907,  0.09073148,  0.08703668,\n",
              "       -0.00788884,  0.01518468, -0.09427509, -0.07360534,  0.09203146,\n",
              "       -0.04222008, -0.01343531,  0.05517178, -0.03677369,  0.04950519,\n",
              "       -0.00418213,  0.14665435, -0.0845378 ,  0.15830807, -0.03887435,\n",
              "       -0.07231962,  0.11479122, -0.1281372 ,  0.17811069,  0.01709322,\n",
              "        0.08093925, -0.01354578,  0.05576634, -0.20447148,  0.01445745,\n",
              "       -0.06025883, -0.08378069, -0.11017103, -0.04826353,  0.08388081,\n",
              "       -0.02029389,  0.1017651 , -0.07488452, -0.07086232, -0.07154382,\n",
              "       -0.09522877, -0.04761662, -0.12064011,  0.05902289, -0.05393305,\n",
              "       -0.00405376, -0.18085414,  0.01787559, -0.17186928, -0.23721239,\n",
              "        0.08092239, -0.13187218, -0.04076278,  0.07269598,  0.0578093 ,\n",
              "       -0.15285103, -0.08504181,  0.06319231,  0.00721982, -0.05508875,\n",
              "        0.1551575 ,  0.08376787,  0.09263211, -0.0440321 ,  0.12657349,\n",
              "       -0.08876016, -0.15951699,  0.00627112, -0.0454142 ,  0.11300067,\n",
              "       -0.02533975, -0.06655723, -0.00812467,  0.200334  ,  0.09871582,\n",
              "        0.07213769,  0.03997885,  0.04372863,  0.01234555,  0.02307541,\n",
              "        0.05063806, -0.04608263, -0.1262972 ,  0.00487611,  0.02638154,\n",
              "       -0.0564509 ,  0.10803585,  0.00048932, -0.1289738 , -0.12122381,\n",
              "        0.010077  , -0.04958693,  0.00594983,  0.10365895,  0.10313626,\n",
              "       -0.1248354 ,  0.09046541,  0.03389014,  0.10527957, -0.06710075,\n",
              "       -0.12512995, -0.02309764,  0.04832941, -0.28466007,  0.04041103,\n",
              "       -0.16758862,  0.0674869 ,  0.01412144,  0.08087724, -0.04323064,\n",
              "       -0.01535801,  0.16552892,  0.06379796,  0.0328032 , -0.09571332,\n",
              "       -0.04211645, -0.11612174, -0.20395778,  0.04037915, -0.01700963,\n",
              "       -0.06515612, -0.03311846,  0.03567337,  0.07176215,  0.07881609,\n",
              "        0.13053058, -0.03544771,  0.06932531, -0.10068574, -0.19001292,\n",
              "        0.15819564, -0.00135086,  0.01084002, -0.00428878, -0.09909407,\n",
              "       -0.01394212, -0.05962569,  0.00637768, -0.15528286, -0.05535723,\n",
              "        0.00225985, -0.13442716,  0.14777835, -0.08826781, -0.05532242,\n",
              "        0.04424854, -0.15774108,  0.0881265 ,  0.07029864,  0.04463721,\n",
              "        0.11854724, -0.16003902,  0.08163955,  0.10901636,  0.03024967,\n",
              "        0.11307999, -0.06210462, -0.14751506,  0.04887448,  0.0404778 ,\n",
              "       -0.03995982,  0.020323  , -0.0913614 , -0.14599286, -0.2403751 ,\n",
              "        0.04527106, -0.10093843, -0.0315193 , -0.01782489, -0.08087848,\n",
              "       -0.03905835, -0.20447087, -0.00765551,  0.11151362, -0.03203868,\n",
              "       -0.05974317,  0.03548573, -0.15203336, -0.03335181, -0.03525638,\n",
              "        0.15789507, -0.10370643,  0.05801561, -0.07345433, -0.0139479 ,\n",
              "        0.01079444, -0.07672253, -0.04657423, -0.09840634, -0.06464728],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lku_BDNEjdKb"
      },
      "source": [
        "#tweet_w2v.save('off-sg.vec')\n",
        "#tweet_w2v.save('fb-en-w2vec-cbow.bin')\n",
        "#tweet_w2v.wv.save_word2vec_format('fb-hi-w2vec-cbow.txt')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyiVN7Yh8ESd"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7VFpm-VjdKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ed819d-c9dc-4152-baa0-338dda810d42"
      },
      "source": [
        "print ('building tf-idf matrix ...')\n",
        "vectorizer = TfidfVectorizer(min_df=1)\n",
        "#matrix = vectorizer.fit_transform(x_train)\n",
        "matrix = vectorizer.fit_transform(train_df['ctext'])\n",
        "\n",
        "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
        "print ('vocab size :', len(tfidf))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tf-idf matrix ...\n",
            "vocab size : 19409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOnxSbRKBOBF"
      },
      "source": [
        "#tweet_w2v['messi']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSS_6lDDjdKi"
      },
      "source": [
        "#tweet_w2v=FastText.load('fb-en-fasttext-sg.vec')\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ei0f2FjdKk"
      },
      "source": [
        "def buildWordVector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += tweet_w2v[word].reshape((1, size)) * tfidf[word]\n",
        "            count += 1.\n",
        "        except KeyError: # handling the case where the token is not\n",
        "                         # in the corpus. useful for testing.\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23vFtP_1jdKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaaba729-0657-4ca1-ef7e-b946c56d89ec"
      },
      "source": [
        "#tweet_w2v=Word2Vec.load('D:/ps/model/English/fasttext/coling-fasttext-eng-cbow.bin')\n",
        "#from gensim.models.wrappers import FastText\n",
        "\n",
        "#tweet_w2v= FastText.load_fasttext_format('D:/ps/model/English/fasttext/coling-fasttext-eng-cbow')\n",
        "\n",
        "n_dim=300\n",
        "from sklearn.preprocessing import scale\n",
        "train_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_train))])\n",
        "train_vecs_w2v = scale(train_vecs_w2v)\n",
        "\n",
        "\n",
        "\n",
        "test_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_test))])\n",
        "test_vecs_w2v = scale(test_vecs_w2v)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "11916it [00:02, 3972.92it/s]\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "1324it [00:00, 4925.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvfCXGfYjdLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b107c818-9178-42ab-b676-78a80f6d34a9"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "dummy_y\n",
        "\n",
        "#encoder = LabelEncoder()\n",
        "#encoder.fit(y_valid)\n",
        "#vencoded_Y = encoder.transform(y_valid)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "#vdummy_y = np_utils.to_categorical(vencoded_Y)\n",
        "#vdummy_y\n",
        "\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "tencoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "tdummy_y = np_utils.to_categorical(tencoded_Y)\n",
        "tdummy_y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mdhsGc8jdLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef2f0d2-92d4-4e40-856e-f8ef678158f2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(Dense(7, activation='relu', input_dim=300))\n",
        "#model.add(Dense(256, activation='relu', input_dim=300))\n",
        "#model.add(Dense(256, activation='relu', input_dim=300))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_vecs_w2v,dummy_y, epochs=12, batch_size=8, verbose=2)#validation_data=(valid_vecs_w2v, vdummy_y),"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "1490/1490 - 2s - loss: 0.6266 - accuracy: 0.6743 - 2s/epoch - 2ms/step\n",
            "Epoch 2/12\n",
            "1490/1490 - 2s - loss: 0.5875 - accuracy: 0.6957 - 2s/epoch - 1ms/step\n",
            "Epoch 3/12\n",
            "1490/1490 - 2s - loss: 0.5744 - accuracy: 0.7069 - 2s/epoch - 1ms/step\n",
            "Epoch 4/12\n",
            "1490/1490 - 1s - loss: 0.5663 - accuracy: 0.7103 - 1s/epoch - 1ms/step\n",
            "Epoch 5/12\n",
            "1490/1490 - 1s - loss: 0.5632 - accuracy: 0.7124 - 1s/epoch - 968us/step\n",
            "Epoch 6/12\n",
            "1490/1490 - 1s - loss: 0.5600 - accuracy: 0.7169 - 1s/epoch - 994us/step\n",
            "Epoch 7/12\n",
            "1490/1490 - 2s - loss: 0.5574 - accuracy: 0.7170 - 2s/epoch - 1ms/step\n",
            "Epoch 8/12\n",
            "1490/1490 - 1s - loss: 0.5542 - accuracy: 0.7234 - 1s/epoch - 986us/step\n",
            "Epoch 9/12\n",
            "1490/1490 - 1s - loss: 0.5540 - accuracy: 0.7219 - 1s/epoch - 985us/step\n",
            "Epoch 10/12\n",
            "1490/1490 - 2s - loss: 0.5525 - accuracy: 0.7260 - 2s/epoch - 1ms/step\n",
            "Epoch 11/12\n",
            "1490/1490 - 2s - loss: 0.5513 - accuracy: 0.7234 - 2s/epoch - 1ms/step\n",
            "Epoch 12/12\n",
            "1490/1490 - 1s - loss: 0.5491 - accuracy: 0.7270 - 1s/epoch - 995us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76c63b2c90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYb27Jj4jdLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46c1a46-a6f9-4ec3-b084-15dbdc273ae5"
      },
      "source": [
        "#score = model.evaluate(valid_vecs_w2v, vdummy_y, batch_size=8, verbose=2)\n",
        "#print (score[1])\n",
        "\n",
        "score = model.evaluate(test_vecs_w2v, tdummy_y, batch_size=8, verbose=2)\n",
        "print (score[1])\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166/166 - 0s - loss: 0.6074 - accuracy: 0.6896 - 307ms/epoch - 2ms/step\n",
            "0.689577043056488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7nPA109k3sf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}